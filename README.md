# Continously Trainable LLM

## This is a simple implemenation of the transformer architeture inspired by Karpathu's microGPT. It is however augmented by the introduction of a weightless neural network (WNN) which by nature are continously trainable. This results in a LLM which has parts of its underlying weights updated in realtime, resulting in more relevent and useful responses.
