# Continously Trainable LLM

This is a simple implemenation of the transformer architeture inspired by Karpathy's microGPT. It is however augmented by the introduction of a weightless neural network (WNN) these by nature are continously trainable. This results in a LLM which has parts of its underlying weights updated in realtime, resulting in more relevent and useful responses.
