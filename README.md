# Continously Trainable LLM

This is a simple implemenation of the transformer architeture inspired by Karpathy's microGPT. It is however augmented by the introduction of a weightless neural network (WNN). These by nature are continously trainable. This results in a LLM which has parts of its underlying weights which can be updated in realtime, resulting in more relevent and useful responses.
